#!/usr/bin/env python3
"""
å¤šå¹³å°çˆ¬è™«ç³»ç»Ÿæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯å„ä¸ªå¹³å°çš„çˆ¬å–åŠŸèƒ½
"""

import sys
import os
import json
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from tools.crawler import MemeCrawler
from config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_single_platform(platform: str, limit: int = 10):
    """æµ‹è¯•å•ä¸ªå¹³å°çˆ¬å–"""
    print(f"\n=== æµ‹è¯•å¹³å°: {platform.upper()} ===")
    
    try:
        crawler = MemeCrawler()
        posts = crawler.crawl_source(platform, limit=limit)
        
        if posts:
            print(f"âœ… æˆåŠŸçˆ¬å– {len(posts)} æ¡å†…å®¹")
            
            # æ˜¾ç¤ºç¬¬ä¸€æ¡å†…å®¹ç¤ºä¾‹
            if posts:
                sample = posts[0]
                print(f"ğŸ“ ç¤ºä¾‹å†…å®¹:")
                print(f"   æ ‡é¢˜: {sample.get('title', 'N/A')}")
                print(f"   ä½œè€…: {sample.get('author', 'N/A')}")
                print(f"   å¹³å°: {sample.get('platform', 'N/A')}")
                print(f"   æ¥æº: {sample.get('source', 'N/A')}")
                
                # æ˜¾ç¤ºå¹³å°ç‰¹å®šæ•°æ®
                if sample.get('platform_specific'):
                    print(f"   å¹³å°æ•°æ®: {sample['platform_specific']}")
        else:
            print(f"âš ï¸  æœªçˆ¬å–åˆ°å†…å®¹")
            
        return posts
        
    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±è´¥: {e}")
        return []

def test_keyword_search():
    """æµ‹è¯•å…³é”®è¯æœç´¢"""
    print(f"\n=== æµ‹è¯•å…³é”®è¯æœç´¢ ===")
    
    try:
        crawler = MemeCrawler()
        keywords = ["æ¢—", "ç½‘ç»œçƒ­è¯", "æç¬‘"]
        
        posts = crawler.crawl_source("all", limit=20, keywords=keywords)
        
        if posts:
            print(f"âœ… é€šè¿‡å…³é”®è¯æœç´¢åˆ° {len(posts)} æ¡å†…å®¹")
            
            # æŒ‰å¹³å°ç»Ÿè®¡
            platform_counts = {}
            for post in posts:
                platform = post.get('platform', 'unknown')
                platform_counts[platform] = platform_counts.get(platform, 0) + 1
            
            print(f"ğŸ“Š å¹³å°åˆ†å¸ƒ: {platform_counts}")
            
            return posts
        else:
            print(f"âš ï¸  å…³é”®è¯æœç´¢æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
            return []
            
    except Exception as e:
        print(f"âŒ å…³é”®è¯æœç´¢å¤±è´¥: {e}")
        return []

def test_all_platforms():
    """æµ‹è¯•æ‰€æœ‰å¹³å°å¹¶è¡Œçˆ¬å–"""
    print(f"\n=== æµ‹è¯•å…¨å¹³å°å¹¶è¡Œçˆ¬å– ===")
    
    try:
        crawler = MemeCrawler()
        
        # å¹¶è¡Œçˆ¬å–æ‰€æœ‰å¹³å°
        posts = crawler.crawl_all_platforms(limit=30)
        
        if posts:
            print(f"âœ… å¹¶è¡Œçˆ¬å–æˆåŠŸï¼Œå…±è·å¾— {len(posts)} æ¡å†…å®¹")
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = crawler.get_engagement_stats(posts)
            print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   æ€»å¸–æ•°: {stats['total_posts']}")
            print(f"   æ€»ç‚¹èµ: {stats['total_likes']}")
            print(f"   æ€»è¯„è®º: {stats['total_comments']}")
            print(f"   å¹³å°åˆ†å¸ƒ: {stats['platform_distribution']}")
            
            return posts
        else:
            print(f"âš ï¸  å¹¶è¡Œçˆ¬å–æœªè·å¾—å†…å®¹")
            return []
            
    except Exception as e:
        print(f"âŒ å¹¶è¡Œçˆ¬å–å¤±è´¥: {e}")
        return []

def test_latest_content():
    """æµ‹è¯•æœ€æ–°å†…å®¹çˆ¬å–"""
    print(f"\n=== æµ‹è¯•æœ€æ–°å†…å®¹çˆ¬å– ===")
    
    try:
        crawler = MemeCrawler()
        keywords = ["æ¢—", "ç½‘ç»œçƒ­è¯"]
        
        posts = crawler.crawl_latest_meme_content(keywords, limit=20)
        
        if posts:
            print(f"âœ… çˆ¬å–åˆ° {len(posts)} æ¡æœ€æ–°å†…å®¹")
            
            # æ˜¾ç¤ºæ—¶é—´åˆ†å¸ƒ
            time_ranges = {
                "1å°æ—¶å†…": 0,
                "1-6å°æ—¶": 0,
                "6-24å°æ—¶": 0,
                "1å¤©ä»¥ä¸Š": 0
            }
            
            now = datetime.now()
            for post in posts[:10]:  # åªåˆ†æå‰10æ¡
                if post.get('timestamp'):
                    time_diff = now - post['timestamp']
                    hours = time_diff.total_seconds() / 3600
                    
                    if hours <= 1:
                        time_ranges["1å°æ—¶å†…"] += 1
                    elif hours <= 6:
                        time_ranges["1-6å°æ—¶"] += 1
                    elif hours <= 24:
                        time_ranges["6-24å°æ—¶"] += 1
                    else:
                        time_ranges["1å¤©ä»¥ä¸Š"] += 1
            
            print(f"â° æ—¶é—´åˆ†å¸ƒ: {time_ranges}")
            
            return posts
        else:
            print(f"âš ï¸  æœªçˆ¬å–åˆ°æœ€æ–°å†…å®¹")
            return []
            
    except Exception as e:
        print(f"âŒ æœ€æ–°å†…å®¹çˆ¬å–å¤±è´¥: {e}")
        return []

def test_engagement_analysis():
    """æµ‹è¯•å‚ä¸åº¦åˆ†æ"""
    print(f"\n=== æµ‹è¯•å‚ä¸åº¦åˆ†æ ===")
    
    try:
        crawler = MemeCrawler()
        
        # å…ˆçˆ¬å–ä¸€äº›å†…å®¹ç”¨äºåˆ†æ
        posts = crawler.crawl_source("bilibili", limit=10)
        
        if posts:
            stats = crawler.get_engagement_stats(posts)
            
            print(f"ğŸ“Š å‚ä¸åº¦åˆ†æç»“æœ:")
            for key, value in stats.items():
                print(f"   {key}: {value}")
            
            return stats
        else:
            print(f"âš ï¸  æ²¡æœ‰å†…å®¹å¯ç”¨äºåˆ†æ")
            return {}
            
    except Exception as e:
        print(f"âŒ å‚ä¸åº¦åˆ†æå¤±è´¥: {e}")
        return {}

def save_test_results(results: dict, filename: str = "crawler_test_results.json"):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    try:
        filepath = os.path.join(os.path.dirname(__file__), filename)
        
        # è½¬æ¢datetimeå¯¹è±¡ä¸ºå­—ç¬¦ä¸²
        serializable_results = {}
        for key, value in results.items():
            if isinstance(value, datetime):
                serializable_results[key] = value.isoformat()
            elif isinstance(value, list):
                serializable_results[key] = [
                    {
                        k: (v.isoformat() if isinstance(v, datetime) else v)
                        for k, v in item.items()
                        if not isinstance(v, datetime) or hasattr(v, 'isoformat')
                    }
                    for item in value[:5]  # åªä¿å­˜å‰5æ¡è®°å½•
                ]
            else:
                serializable_results[key] = value
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¤šå¹³å°çˆ¬è™«ç³»ç»Ÿæµ‹è¯•")
    print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # å­˜å‚¨æµ‹è¯•ç»“æœ
    test_results = {}
    
    # æµ‹è¯•å„ä¸ªå¹³å°
    platforms = ["bilibili", "weibo", "tieba", "zhihu", "xiaohongshu"]
    
    for platform in platforms:
        posts = test_single_platform(platform, limit=5)
        test_results[f"{platform}_posts"] = posts
        test_results[f"{platform}_count"] = len(posts)
    
    # æµ‹è¯•å…³é”®è¯æœç´¢
    keyword_posts = test_keyword_search()
    test_results["keyword_posts"] = keyword_posts
    test_results["keyword_count"] = len(keyword_posts)
    
    # æµ‹è¯•å…¨å¹³å°å¹¶è¡Œçˆ¬å–
    all_posts = test_all_platforms()
    test_results["all_platforms_posts"] = all_posts
    test_results["all_platforms_count"] = len(all_posts)
    
    # æµ‹è¯•æœ€æ–°å†…å®¹
    latest_posts = test_latest_content()
    test_results["latest_posts"] = latest_posts
    test_results["latest_count"] = len(latest_posts)
    
    # æµ‹è¯•å‚ä¸åº¦åˆ†æ
    engagement_stats = test_engagement_analysis()
    test_results["engagement_stats"] = engagement_stats
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print(f"\n" + "="*50)
    print(f"ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print(f"="*50)
    
    total_successful_crawls = sum(
        test_results.get(f"{platform}_count", 0) 
        for platform in platforms
    )
    
    print(f"âœ… å•å¹³å°çˆ¬å–æˆåŠŸ: {total_successful_crawls} æ¡å†…å®¹")
    print(f"âœ… å…³é”®è¯æœç´¢: {test_results.get('keyword_count', 0)} æ¡å†…å®¹")
    print(f"âœ… å…¨å¹³å°å¹¶è¡Œ: {test_results.get('all_platforms_count', 0)} æ¡å†…å®¹")
    print(f"âœ… æœ€æ–°å†…å®¹: {test_results.get('latest_count', 0)} æ¡å†…å®¹")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    save_test_results(test_results)
    
    print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    return test_results

if __name__ == "__main__":
    main()